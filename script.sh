#!/bin/bash
#
# This script reads the file path from its arguments.
#
# Arg 1: The Elasticsearch cluster URL (e.g., http://elastic:changeme@localhost:9200)
# Arg 2: The file path or glob pattern (e.g., 'logs.txt' or 'logs/*.log')
#

# --- Colors for output ---
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# --- Greeting ---
echo -e "${PURPLE}üöÄ YOLO Log Uploader${NC}"
echo -e "${CYAN}=================================${NC}"

# --- 1. Get Arguments ---
CLUSTER_URL="$1"
FILE_PATTERN="$2"

# --- 2. Validation ---
if [ -z "$CLUSTER_URL" ]; then
  echo -e "${RED}‚ùå Error: Cluster URL (Arg 1) is required.${NC}" >&2
  exit 1
fi
if [ -z "$FILE_PATTERN" ]; then
  echo -e "${RED}‚ùå Error: File path/glob (Arg 2) is required.${NC}" >&2
  exit 1
fi

# --- 3. Show what we're doing ---
echo -e "${BLUE}üì° Target:${NC} ${CLUSTER_URL}/logs"
echo -e "${YELLOW}üìÅ Files to upload:${NC}"

# Check if files exist and show them with line counts
files_found=false
total_lines=1
for file in $(eval echo $FILE_PATTERN); do
  if [ -f "$file" ]; then
    line_count=$(wc -l < "$file")
    echo -e "  ${GREEN}‚úì${NC} $file (${CYAN}${line_count}${NC} lines)"
    files_found=true
    total_lines=$((total_lines + line_count))
  fi
done

if [ "$files_found" = false ]; then
  echo -e "${RED}‚ùå No files found matching pattern: $FILE_PATTERN${NC}"
  exit 1
fi

echo -e "${YELLOW}üìä Total lines to upload: ${CYAN}${total_lines}${NC}"

# Configure batch size (lines per batch)
BATCH_SIZE=1000
if [ $total_lines -gt $BATCH_SIZE ]; then
  estimated_batches=$(( (total_lines + BATCH_SIZE - 1) / BATCH_SIZE ))
  echo -e "${BLUE}üì¶ Batching enabled: ${CYAN}${estimated_batches}${NC} batches of ${CYAN}${BATCH_SIZE}${NC} lines each"
fi

echo -e "${CYAN}---------------------------------${NC}"
echo -e "${YELLOW}‚è≥ Uploading logs...${NC}"

# --- Show preview of the request format ---
echo -e "${BLUE}üìã Request Preview (first 3 log lines):${NC}"
echo -e "${CYAN}---${NC}"
echo -e "${PURPLE}POST /logs/_bulk${NC}"

preview_count=0
eval "cat $FILE_PATTERN" | head -3 | \
awk '{
  gsub(/\\/, "\\\\");
  gsub(/"/, "\\\"");
  gsub(/\r/, "\\\\r");
  gsub(/\n/, "\\\\n");
  gsub(/\t/, "\\\\t");
  gsub(/\f/, "\\\\f");
  gsub(/\b/, "\\\\b");
  printf "{\"create\":{}}\n{\"message\":\"%s\"}\n", $0
}' | while IFS= read -r line; do
  echo "$line"
done

echo -e "${CYAN}---${NC}"
echo -e "${BLUE}üí° Each log line becomes 2 JSON lines: a 'create' action + the message${NC}"
echo -e "${BLUE}üåê Sending to: ${TARGET_URL}${NC}"
echo -e "${CYAN}---------------------------------${NC}"

# --- 4. Build full URL with fixed index ---
CLUSTER_URL_WITH_INDEX="${CLUSTER_URL}/logs"

# --- 5. Build curl options ---
TARGET_URL="${CLUSTER_URL_WITH_INDEX}/_bulk?filter_path=took,errors,items.*.error"

curl_opts=(
  -s
  -XPOST
  "$TARGET_URL"
  -H "Content-Type: application/x-ndjson"
  --data-binary @-
)

# Note: No API key support since we're using basic auth in URL

# --- 6. Run the full pipeline ---
# This command 'cats' the file(s) from Arg 2,
# pipes them to your awk command,
# and pipes the result to curl in batches.
#
# 'eval' is used so that glob patterns like 'logs/*.log' are expanded.

batch_count=0
total_processed=0
overall_success=true

# Function to process a batch
process_batch() {
  local batch_data="$1"
  local batch_num="$2"
  
  if [ -n "$batch_data" ]; then
    echo -e "${BLUE}üì§ Processing batch ${batch_num}...${NC}"
    
    response=$(echo "$batch_data" | curl "${curl_opts[@]}")
    local curl_exit_code=$?
    
    if [ $curl_exit_code -eq 0 ]; then
      if echo "$response" | grep -q 'root_cause\|"errors":true'; then
        echo -e "${YELLOW}‚ö†Ô∏è  Batch ${batch_num} had some errors${NC}"
        echo "$response"
        return 1  # Return error status instead of setting variable
      else
        echo -e "${GREEN}‚úÖ Batch ${batch_num} completed successfully${NC}"
        return 0
      fi
    else
      echo -e "${RED}‚ùå Batch ${batch_num} failed!${NC}"
      echo "$response"
      return 1
    fi
  fi
  return 0
}

# Process files with batching
current_batch=""
lines_in_batch=0
temp_file=$(mktemp)

eval "cat $FILE_PATTERN" | \
awk '{
  gsub(/\\/, "\\\\");
  gsub(/"/, "\\\"");
  gsub(/\r/, "\\\\r");
  gsub(/\n/, "\\\\n");
  gsub(/\t/, "\\\\t");
  gsub(/\f/, "\\\\f");
  gsub(/\b/, "\\\\b");
  printf "{\"create\":{}}\n{\"message\":\"%s\"}\n", $0
}' | \
while IFS= read -r line; do
  current_batch="${current_batch}${line}\n"
  lines_in_batch=$((lines_in_batch + 1))
  total_processed=$((total_processed + 1))
  
  # Check if we've reached batch size (every 2 lines = 1 document)
  if [ $((lines_in_batch / 2)) -ge $BATCH_SIZE ]; then
    batch_count=$((batch_count + 1))
    echo -ne "$current_batch" | process_batch "$(cat)" $batch_count
    if [ $? -ne 0 ]; then
      echo "error" >> "$temp_file"
    fi
    current_batch=""
    lines_in_batch=0
  fi
done

# Process remaining lines in final batch
if [ -n "$current_batch" ] && [ $lines_in_batch -gt 0 ]; then
  batch_count=$((batch_count + 1))
  echo -ne "$current_batch" | process_batch "$(cat)" $batch_count
  if [ $? -ne 0 ]; then
    echo "error" >> "$temp_file"
  fi
fi

# Check if there were any errors
if [ -s "$temp_file" ]; then
  overall_success=false
fi
rm -f "$temp_file"

# Summary of batching
if [ $batch_count -gt 1 ]; then
  echo -e "${CYAN}üìä Processed ${batch_count} batches total${NC}"
fi

# --- 7. Check the result ---
if [ "$overall_success" = true ]; then
  echo -e "${GREEN}‚úÖ All uploads completed successfully!${NC}"
  echo -e "${GREEN}üéâ All documents uploaded without errors!${NC}"
else
  echo -e "${YELLOW}‚ö†Ô∏è  Upload completed with some warnings/errors${NC}"
  echo -e "${YELLOW}Check the batch messages above for details${NC}"
fi

echo -e "${CYAN}=================================${NC}"
echo -e "${PURPLE}‚ú® YOLO Upload Complete! ‚ú®${NC}"
